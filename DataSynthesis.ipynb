{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataSynthesis is a framework to generate data files based on the input spec. It generates real-looking but fake data. Referential integrity is maintained across multiple files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from FakeWrapper.ipynb\n",
      "importing Jupyter notebook from Utils.ipynb\n",
      "importing Jupyter notebook from Lookup.ipynb\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import yaml\n",
    "from yaml.loader import SafeLoader\n",
    "import random\n",
    "import import_ipynb\n",
    "from FakeWrapper import FakeWrapper\n",
    "from Utils import Utils\n",
    "from Lookup import Lookup\n",
    "import os\n",
    "from datetime import date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Synthesis():\n",
    "    def __init__(self,opbasefilename,\n",
    "                 numrows=1,colsep=',',\n",
    "                 opextension='.dat',\n",
    "                 specextension='.yaml',\n",
    "                 filedate=date.today().strftime('%Y%m%d'),\n",
    "                 datadir = './data/',\n",
    "                 configdir = './config/'):\n",
    "        self.opbasefilename = opbasefilename\n",
    "        self.specfilename = opbasefilename + specextension\n",
    "        self.numrows = numrows\n",
    "        self.colsep = colsep\n",
    "        self.opfilenameext = opextension\n",
    "        self.filedate = filedate\n",
    "        self.fhandle = Utils()\n",
    "        self.faker = FakeWrapper()\n",
    "        self.datadir = datadir\n",
    "        self.configdir = configdir\n",
    "    \n",
    "    def synthesis(self):\n",
    "        \n",
    "        fopen = self.fhandle.openfile(f'{self.configdir}{self.specfilename}',permission='r+')\n",
    "        specread = self.fhandle.load_yaml(fopen)\n",
    "        df = pd.DataFrame()\n",
    "        \n",
    "        for columnnames in specread[self.opbasefilename]['columnnames']:\n",
    "            for header, values in columnnames.items():\n",
    "                if values['lookup'] != None:\n",
    "                    self.lkey = Lookup(lookup=values['lookup'],\n",
    "                                            matchon= '.' if values['matchon'] == None else values['matchon'],\n",
    "                                            filedate=self.filedate,\n",
    "                                            extension=self.opfilenameext,\n",
    "                                            datadir=self.datadir)\n",
    "                    \n",
    "                    if values['matchon'] != None:\n",
    "                        self.lkey.load_dataframe()\n",
    "                        #Handle for none matchby\n",
    "                        values['matchby'] = values['matchon'].split('.')[1] if values['matchby'] == None else values['matchby']\n",
    "                        df[header] = self.lkey.matched_series(df[values['matchby']].to_frame())\n",
    "                        if values['fakerprovider'] == 'price_in_range':\n",
    "                            df[header] = df.apply(lambda row : self.faker.getfake(values['fakerprovider'],{'input_price':row[header]}),axis=1)                                             \n",
    "                    else:\n",
    "                        self.lkey.load_series()\n",
    "                        df[header] = [self.lkey.random_foreign_value() for i in range(self.numrows)]\n",
    "                else:\n",
    "                    df[header] = [self.faker.getuniquefake(values['fakerprovider'],values['fakerarguments']) \n",
    "                                  if values['candidatekey'] == True\n",
    "                                  else self.faker.getfake(values['fakerprovider'],values['fakerarguments'])\n",
    "                                  for i in range(self.numrows)]\n",
    "\n",
    "        self.fhandle.df_to_csv(df,f'{self.datadir}{self.opbasefilename}')\n",
    "        self.fhandle.rename_with_date(f'{self.datadir}{self.opbasefilename}',self.opfilenameext,self.filedate)\n",
    "        return df\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actimize03_RefPrice\n",
      "{'numrows': 100000, 'extension': '.dat'}\n",
      "Actimize01_Orders\n",
      "{'numrows': 10000, 'extension': '.dat'}\n",
      "Actimize02_Executions\n",
      "{'numrows': 500, 'extension': '.dat'}\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    seq_utils = Utils()\n",
    "    seq_loader = seq_utils.openfile('./config/Sequence.yaml')\n",
    "    seq_stream = seq_utils.load_yaml(seq_loader)\n",
    "    \n",
    "    for key, value in seq_stream.items():\n",
    "        for list_of_files in value:\n",
    "            for file_to_synthesize, properties in list_of_files.items():\n",
    "                print(file_to_synthesize)\n",
    "                print(properties)\n",
    "                syn = Synthesis(file_to_synthesize,properties['numrows'],properties['extension'])\n",
    "                df = syn.synthesis()\n",
    "                del(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
